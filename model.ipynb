{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mes débuts avec spaCY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# load a pre-trained spaCy language model\n",
    "# doit installer le module : python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spacy.load : function used to load a spaCy language model.\n",
    "\n",
    "\"en_core_web_sm\" : This is the name of the pre-trained language model. In this case, it is the small English model provided by spaCy. The model includes vocabulary, syntax, and entities trained on a large corpus of English text.\n",
    "\n",
    "By loading this model, you can use it to process and analyze English text, including tasks like tokenization, part-of-speech tagging, named entity recognition, and syntactic dependency parsing.\n",
    "\n",
    "After loading the model, nlp becomes a callable object that you can use to process text, as shown in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "\n",
    "# This processes the text and returns a Doc object containing the linguistic annotations.\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K. PROPN dobj\n",
      "startup NOUN dep\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "1 NUM compound\n",
      "billion NUM pobj\n"
     ]
    }
   ],
   "source": [
    "# accéder aux informations\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explication sur les résultats du NLP\n",
    "\n",
    "Each token is analyzed for its grammatical role in the sentence, which helps in understanding the structure and meaning of the text.\n",
    "Le résultat est :\n",
    "token text - indication on the nature of this part -  Syntactic dependency indicating\n",
    "\n",
    "Donc par exemple pour notre exemple :\n",
    "Apple: The token text - PROPN: Part-of-speech tag indicating it's a proper noun - Syntactic dependency indicating it's the nominal subject of the sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
